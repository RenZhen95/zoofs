{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSI_BPSO.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSTwzHyBlmsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import lightgbm as lgb\n",
        "clf = lgb.LGBMClassifier(random_state=2)\n",
        "runs=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_C_OmHY3C7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bdd7ee95-1050-4800-ccf8-ba9c58a4c990"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7l_MklY3Jz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame({'v1':newsgroups_train.target,'v2':newsgroups_train.data})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvY028YOKhiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df=pd.read_csv('/content/spam.csv',encoding='latin1')\n",
        "df=df[['v1','v2']]\n",
        "df_target=df['v1']\n",
        "df_target=df_target.replace('spam',1).replace('ham',0)\n",
        "df=df.drop(columns=['v1'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(df,df_target, test_size=0.80, random_state=42,stratify=df_target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train,y_train, test_size=0.30, random_state=42,stratify=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4bZhz4jLW4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(\n",
        "    lowercase=True,stop_words = 'english',max_features=300,min_df=0.01\n",
        ")\n",
        "tfidf.fit( X_train['v2'].astype('str') )\n",
        "\n",
        "def returnCV(df,tfidf):\n",
        "  text = tfidf.transform( df['v2'].values )\n",
        "  txt_features_cols = ['feat_' + col.replace(' ','_') for col in tfidf.get_feature_names()]\n",
        "  txt_features = pd.DataFrame(text.todense(), columns=txt_features_cols)\n",
        "  return txt_features.reset_index(drop=True)\n",
        "\n",
        "X_train=returnCV(X_train,tfidf)\n",
        "X_test=returnCV(X_test,tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9eR_8DxMFwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8eac39e-c0bc-4094-c280-e949102fb2ef"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1583, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVYU77oTmR_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df=pd.read_csv('/content/musk_csv.csv')\n",
        "# df=df.copy()\n",
        "# df_target=df['class']\n",
        "# df=df.drop(columns=['ID','molecule_name','conformation_name','class'])\n",
        "# X_train, X_test, y_train, y_test = train_test_split(df,df_target, test_size=0.30, random_state=42,stratify=df_target)\n",
        "# name='Musk'\n",
        "# X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtBIuKHDmeTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_shape=X_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og_YeThHmgr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "from sklearn.metrics import log_loss\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "def score_model(model,X_train, y_train, X_valid, y_valid):\n",
        "    model.fit(X_train,y_train)\n",
        "    # return log_loss(y_valid,model.predict_proba(X_valid))\n",
        "    P = (model.predict(X_valid) != y_valid).mean()\n",
        "    alpha=0.01\n",
        "    # Compute for the objective function\n",
        "    j = alpha*(X_valid.shape[1]/data_shape)+(1-alpha)*P\n",
        "    return j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZxdamoMmiDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SwarmGenerator:\n",
        "\n",
        "  def __init__(self,objective_function,n_iteration=50,population_size=50,\n",
        "               c1=2,c2=2,w=0.9):\n",
        "    self.population_size = population_size\n",
        "    self.n_iteration=n_iteration\n",
        "    self.historical_score_record=[]\n",
        "    self.objective_function=objective_function\n",
        "    self.c1=c1\n",
        "    self.c2=c2\n",
        "    self.w=w\n",
        "\n",
        "  def initialize_population(self,X):\n",
        "        self.individuals =  np.random.randint(0,2,size=(self.population_size,X.shape[1]))\n",
        "\n",
        "\n",
        "  def evaluate_fitness(self,model,X_train,y_train,X_valid,y_valid):\n",
        "        scores =  []\n",
        "        for i,individual in enumerate(self.individuals):\n",
        "            chosen_features = [index for index in range(X_train.shape[1]) if individual[index]==1]\n",
        "            X_train_copy = X_train.iloc[:,chosen_features]\n",
        "            X_valid_copy = X_valid.iloc[:,chosen_features]\n",
        "            score = self.objective_function(model,X_train_copy,y_train,X_valid_copy,y_valid)\n",
        "            if score< self.current_best_scores[i]:\n",
        "              self.current_best_scores[i]=score\n",
        "              self.current_best_individual_score_dimensions[i]=individual\n",
        "\n",
        "            scores.append(score)\n",
        "        self.fitness_scores = scores\n",
        " \n",
        "\n",
        "  def sigmoid(self,x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "        \n",
        "  def fit(self,model,X_train,y_train,X_valid,y_valid):\n",
        "    list_best_fitness=[]\n",
        "    list_mean_fitness=[]\n",
        "    list_min_fitness=[]\n",
        "\n",
        "    self.initialize_population(X_train)\n",
        "\n",
        "    self.best_score=np.inf\n",
        "    self.best_dim=np.ones(X_train.shape[1]) \n",
        "\n",
        "    self.current_best_individual_score_dimensions=self.individuals\n",
        "    self.current_best_scores = [np.inf]*self.population_size \n",
        "    self.gbest_individual=self.best_dim\n",
        "    self.v=np.zeros((self.population_size,X_train.shape[1]))\n",
        "\n",
        "    for i in range(self.n_iteration):\n",
        "      if (self.individuals.sum(axis=1)==0).sum()>0:\n",
        "        print((self.individuals.sum(axis=1)==0).sum(),' individuals went zero')\n",
        "        self.individuals[self.individuals.sum(axis=1)==0]=np.random.randint(0,2,(self.individuals[self.individuals.sum(axis=1)==0].shape[0],\\\n",
        "                                                                                self.individuals[self.individuals.sum(axis=1)==0].shape[1]))\n",
        "      self.evaluate_fitness(model,X_train,y_train,X_valid,y_valid)\n",
        "\n",
        "      if np.array(self.fitness_scores).min()<self.best_score:\n",
        "        self.best_dim=self.individuals[np.array(self.fitness_scores).argmin()]\n",
        "        self.best_score=np.array(self.fitness_scores).min()\n",
        "      self.gbest_individual=self.best_dim       \n",
        "\n",
        "      r1=np.random.random((self.population_size,X_train.shape[1]))\n",
        "      r2=np.random.random((self.population_size,X_train.shape[1]))\n",
        "    \n",
        "      self.v=self.w*self.v+self.c1*r1*(self.gbest_individual-self.individuals)+\\\n",
        "      self.c2*r2*(self.current_best_individual_score_dimensions-self.individuals)\n",
        "      self.v=np.where(self.v>6,6,self.v)\n",
        "      self.v=np.where(self.v<-6,-6,self.v)\n",
        "\n",
        "      list_best_fitness.append(self.best_score)\n",
        "      list_mean_fitness.append(np.array(self.fitness_scores).mean())\n",
        "      list_min_fitness.append(np.array(self.fitness_scores).min())\n",
        "      \n",
        "      \n",
        "      self.s_v=self.sigmoid(self.v)\n",
        "\n",
        "      self.individuals=np.where(np.random.uniform(size=(self.population_size,X_train.shape[1]))<self.s_v,1,0)\n",
        "\n",
        "    return self.best_dim,   list_best_fitness,\\\n",
        "                list_mean_fitness,list_min_fitness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYyCCXgOmjb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b93f2a-fc5a-4ce4-f5c1-329692a5c960"
      },
      "source": [
        "list_best_fitness_org=[]\n",
        "list_mean_fitness_org=[]\n",
        "list_min_fitness_org=[]\n",
        "list_res_org=[]\n",
        "for i in range(runs):\n",
        "  print(i)\n",
        "  gaf=SwarmGenerator(score_model,100,10)\n",
        "  res,temp1,temp2,temp3=gaf.fit(clf,X_train, y_train,X_test, y_test)\n",
        "  list_res_org.append(res)\n",
        "  list_best_fitness_org.append(temp1)\n",
        "  list_mean_fitness_org.append(temp2)\n",
        "  list_min_fitness_org.append(temp3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8ZjmAvtmkuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SwarmGenerator_nope:\n",
        "\n",
        "  def __init__(self,objective_function,n_iteration=50,population_size=50,\n",
        "               c1=2,c2=2,w=0.9):\n",
        "    self.population_size = population_size\n",
        "    self.n_iteration=n_iteration\n",
        "    self.historical_score_record=[]\n",
        "    self.objective_function=objective_function\n",
        "    self.c1=c1\n",
        "    self.c2=c2\n",
        "    self.w=w\n",
        "\n",
        "  def initialize_population(self,X):\n",
        "        self.individuals =  np.random.randint(0,2,size=(self.population_size,X.shape[1]))\n",
        "\n",
        "\n",
        "  def evaluate_fitness(self,model,X_train,y_train,X_valid,y_valid):\n",
        "        scores =  []\n",
        "        for i,individual in enumerate(self.individuals):\n",
        "            chosen_features = [index for index in range(X_train.shape[1]) if individual[index]==1]\n",
        "            X_train_copy = X_train.iloc[:,chosen_features]\n",
        "            X_valid_copy = X_valid.iloc[:,chosen_features]\n",
        "            score = self.objective_function(model,X_train_copy,y_train,X_valid_copy,y_valid)\n",
        "            if score< self.current_best_scores[i]:\n",
        "              self.current_best_scores[i]=score\n",
        "              self.current_best_individual_score_dimensions[i]=individual\n",
        "\n",
        "            scores.append(score)\n",
        "        self.fitness_scores = scores\n",
        " \n",
        "\n",
        "  def sigmoid(self,x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "        \n",
        "  def fit(self,model,X_train,y_train,X_valid,y_valid):\n",
        "    list_best_fitness=[]\n",
        "    list_mean_fitness=[]\n",
        "    list_min_fitness=[]\n",
        "    self.initialize_population(X_train)\n",
        "\n",
        "    self.best_score=np.inf\n",
        "    self.best_dim=np.ones(X_train.shape[1]) \n",
        "    values_list=[]\n",
        "\n",
        "    self.current_best_individual_score_dimensions=self.individuals\n",
        "    self.current_best_scores = [np.inf]*self.population_size \n",
        "    self.gbest_individual=self.best_dim\n",
        "    self.v=np.zeros((self.population_size,X_train.shape[1]))\n",
        "\n",
        "    for i in range(self.n_iteration):\n",
        "      if (self.individuals.sum(axis=1)==0).sum()>0:\n",
        "        print((self.individuals.sum(axis=1)==0).sum(),' individuals went zero')\n",
        "        self.individuals[self.individuals.sum(axis=1)==0]=np.random.randint(0,2,(self.individuals[self.individuals.sum(axis=1)==0].shape[0],\\\n",
        "                                                                                self.individuals[self.individuals.sum(axis=1)==0].shape[1]))\n",
        "      self.evaluate_fitness(model,X_train,y_train,X_valid,y_valid)\n",
        "\n",
        "      \n",
        "\n",
        "      if np.array(self.fitness_scores).min()<self.best_score:\n",
        "        self.best_dim=self.individuals[np.array(self.fitness_scores).argmin()]\n",
        "        self.best_score=np.array(self.fitness_scores).min()\n",
        "      self.gbest_individual=self.best_dim\n",
        "\n",
        "      \n",
        "      temp=list(X_train.columns[np.where( self.individuals[np.array(self.fitness_scores).argmin()] )])\n",
        "\n",
        "       \n",
        "      r1=np.random.random((self.population_size,X_train.shape[1]))\n",
        "      r2=np.random.random((self.population_size,X_train.shape[1]))\n",
        "\n",
        "      self.fitness_scores_numpy=np.array(self.fitness_scores)\n",
        "      self.qi=np.array(self.fitness_scores_numpy-self.fitness_scores_numpy.max())/(self.fitness_scores_numpy.min()-self.fitness_scores_numpy.max())\n",
        "      self.Mi=self.qi\n",
        "      self.Mi=2*self.Mi-1\n",
        "    \n",
        "\n",
        "      temp=self.individuals\n",
        "      temp_2=(( (temp.reshape(temp.shape[0],1,temp.shape[1])-temp.reshape(1,temp.shape[0],temp.shape[1])).reshape(temp.shape[0]**2,temp.shape[1])**2) )\n",
        "      temp_3=np.delete(temp_2,tuple(np.arange(0,temp.shape[0]**2,temp.shape[0]+1)),axis=0 ).reshape(temp.shape[0],temp.shape[0]-1,temp.shape[1]).sum(axis=2)\n",
        "\n",
        "      temp_4=np.where(temp_3<int(X_train.shape[1]/2) )\n",
        "      temp_4_R0=np.where(temp_3<int(X_train.shape[1]/4))\n",
        "      \n",
        "     \n",
        "      self.acc=[]\n",
        "      self.acc_R0=[]\n",
        "\n",
        "      self.acc_individual=[]\n",
        "\n",
        "      Mi=self.Mi\n",
        "      for ind_index,individual in enumerate(temp):   \n",
        "        indexs=np.argsort(self.Mi[temp_4[1][np.where(temp_4[0]==ind_index)]] )[:int(len(temp_4[1][np.where(temp_4[0]==ind_index)])/1)]\n",
        "        indexs_R0=np.argsort(self.Mi[temp_4_R0[1][np.where(temp_4_R0[0]==ind_index)]] )[:int(len(temp_4_R0[1][np.where(temp_4_R0[0]==ind_index)])/1)] \n",
        "        \n",
        "        temp_5=temp[indexs]*np.repeat(Mi[indexs],temp.shape[1]).reshape(Mi[indexs].shape[0],temp.shape[1]) \n",
        "        temp_6=temp_5.sum(axis=0)/(temp[indexs].sum(axis=0))\n",
        "        temp_6[np.isnan(temp_6)] = 0\n",
        "\n",
        "        acc1=temp_6\n",
        "\n",
        "   \n",
        "        self.acc.append(list(temp_6))\n",
        "\n",
        "        temp_5=temp[indexs_R0]*np.repeat(Mi[indexs_R0],temp.shape[1]).reshape(Mi[indexs_R0].shape[0],temp.shape[1]) \n",
        "        temp_6=temp_5.sum(axis=0)/(temp[indexs_R0].sum(axis=0))\n",
        "        temp_6[np.isnan(temp_6)] = 0\n",
        "        self.acc_R0.append(list(temp_6))\n",
        "\n",
        "        temp_6=(0.8*acc1+0.2*temp_6)\n",
        "\n",
        "        self.acc_individual.append( list(self.individuals[np.sqrt(((self.individuals-temp_6)**2).sum(axis=1)).argmin()]))\n",
        "\n",
        "      self.acc=np.array(self.acc)\n",
        "      self.acc_R0=np.array(self.acc_R0)\n",
        "\n",
        "      values_list.append(self.best_score )\n",
        "      \n",
        "      r3=np.random.random((self.population_size,X_train.shape[1]))\n",
        "      r4=np.random.random((self.population_size,X_train.shape[1]))\n",
        "\n",
        "      self.v=self.w*(self.v ) +self.c1*r1*(  (self.gbest_individual ) -self.individuals)+\\\n",
        "       self.c2*r2*( (self.current_best_individual_score_dimensions  ) -self.individuals)+2*r3*( np.array(self.acc_individual)-self.individuals )#+2*r4*( np.array(self.acc_individual2)-self.individuals )\n",
        "\n",
        "      self.v=np.where(self.v>6,6,self.v)\n",
        "      self.v=np.where(self.v<-6,-6,self.v)\n",
        "\n",
        "      list_best_fitness.append(self.best_score)\n",
        "      list_mean_fitness.append(np.array(self.fitness_scores).mean())\n",
        "      list_min_fitness.append(np.array(self.fitness_scores).min())\n",
        "      \n",
        "      self.s_v=self.sigmoid(self.v)\n",
        "\n",
        "      rand_nums=np.random.uniform(size=(self.population_size,X_train.shape[1]))\n",
        "      self.individuals=np.where(rand_nums<self.s_v,1,0)\n",
        "\n",
        "    return self.best_dim,   list_best_fitness,\\\n",
        "                list_mean_fitness,list_min_fitness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ3Xrzw-mp_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "list_best_fitness_new=[]\n",
        "list_mean_fitness_new=[]\n",
        "list_min_fitness_new=[]\n",
        "list_res_new=[]\n",
        "for i in range(runs):\n",
        "  print(i)\n",
        "  gaf=SwarmGenerator_nope(score_model,100,10)\n",
        "  res,temp1,temp2,temp3=gaf.fit(clf,X_train, y_train,X_test, y_test)\n",
        "  list_res_new.append(res)\n",
        "  list_best_fitness_new.append(temp1)\n",
        "  list_mean_fitness_new.append(temp2)\n",
        "  list_min_fitness_new.append(temp3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27d9UWCMmtAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "\n",
        "class GAFeatureSelector:\n",
        "\n",
        "    def __init__(self,objective_function,selective_pressure=2,elitism=2,mutation_rate=0.05,\n",
        "                                                     n_generations=50,population_size=50):\n",
        "        self.n_generations = n_generations\n",
        "        self.selective_pressure = selective_pressure\n",
        "        self.population_size = population_size\n",
        "        self.objective_function = objective_function\n",
        "        self.elitism = elitism\n",
        "        self.mutation_rate = mutation_rate\n",
        "\n",
        "\n",
        "    def evaluate_fitness(self,model,X_train,y_train,X_valid,y_valid):\n",
        "        scores =  []\n",
        "        for individual in self.individuals:\n",
        "            chosen_features = [index for index in range(X_train.shape[1]) if individual[index]==1]\n",
        "            X_train_copy = X_train.iloc[:,chosen_features]\n",
        "            X_valid_copy = X_valid.iloc[:,chosen_features]\n",
        "            score = self.objective_function(model,X_train_copy,y_train,X_valid_copy,y_valid)\n",
        "            scores.append(score)\n",
        "\n",
        "        self.fitness_scores = scores\n",
        "        current_best_score = np.max(self.fitness_scores)\n",
        "        if current_best_score > self.best_score:\n",
        "            self.best_score = current_best_score\n",
        "            self.best_feature_set = self.individuals[np.argmax(self.fitness_scores),:]\n",
        "\n",
        "        ranks = scipy.stats.rankdata(scores,method = 'average')\n",
        "        self.fitness_ranks = self.selective_pressure * ranks\n",
        "\n",
        "\n",
        "    def select_individuals(self,model, X_train, y_train, X_valid, y_valid):\n",
        "        self.evaluate_fitness(model, X_train, y_train, X_valid, y_valid)\n",
        "\n",
        "        sorted_individuals_fitness  = sorted(zip(self.individuals,self.fitness_ranks),key=lambda x:x[1],reverse=True)\n",
        "        elite_individuals = np.array([individual for individual,fitness in sorted_individuals_fitness[:self.elitism]])\n",
        "\n",
        "        #Selecting Non elite individuals with probability proportional to their fitness\n",
        "        non_elite_individuals = np.array([individual[0] for individual in sorted_individuals_fitness[self.elitism:]])\n",
        "\n",
        "        non_elite_individuals_fitness = [individual[1] for individual in sorted_individuals_fitness[self.elitism:]]\n",
        "        selection_probability = non_elite_individuals_fitness/np.sum(non_elite_individuals_fitness)\n",
        "\n",
        "        selected_indices = np.random.choice(range(len(non_elite_individuals)),self.population_size//2, p=selection_probability)\n",
        "        selected_individuals = non_elite_individuals[selected_indices,:]\n",
        "        self.fit_individuals = np.vstack((elite_individuals,selected_individuals))\n",
        "\n",
        "    #Make me a mutant!\n",
        "    def mutate(self,array):\n",
        "        # random_array = np.random.choice([0,1],size=(len(array)),p=[self.mutation_rate,1-self.mutation_rate])\n",
        "        # xor_array = np.bitwise_xor(array, random_array).astype(np.bool)\n",
        "        # mutated_array = np.invert(xor_array).astype(int)\n",
        "        mutated_array = np.copy(array)\n",
        "        for idx, gene in enumerate(array):\n",
        "            if np.random.uniform() < self.mutation_rate:\n",
        "                array[idx] = 1 if gene == 0 else 0\n",
        "\n",
        "        return mutated_array\n",
        "\n",
        "    def produce_next_generation(self):\n",
        "        new_population = np.empty(shape=(self.population_size,self.individuals.shape[1]),dtype=np.int32)\n",
        "        #Time to produce mutant babies, YAY!\n",
        "        for i in range(0,self.population_size,2):\n",
        "            parents = self.fit_individuals[np.random.choice(self.fit_individuals.shape[0], 2, replace=False), :]\n",
        "            crossover_index = np.random.randint(0,len(self.individuals[0]))\n",
        "            new_population[i] = np.hstack((parents[0][:crossover_index],parents[1][crossover_index:]))\n",
        "            new_population[i+1] = np.hstack((parents[1][:crossover_index],parents[0][crossover_index:]))\n",
        "\n",
        "            new_population[i] = self.mutate(new_population[i])\n",
        "            new_population[i+1] =  self.mutate(new_population[i+1])\n",
        "        self.individuals = new_population\n",
        "\n",
        "    def initialize_population(self,X):\n",
        "        self.individuals =  np.random.randint(0,2,size=(self.population_size,X.shape[1]))\n",
        "\n",
        "    def fit(self,model,X_train,y_train,X_valid,y_valid):\n",
        "        list_best_fitness=[]\n",
        "        list_mean_fitness=[]\n",
        "        list_min_fitness=[]\n",
        "        self.initialize_population(X_train)\n",
        "        self.best_score = -1 * np.float(np.inf)\n",
        "        self.best_scores = []\n",
        "\n",
        "        for i in range(self.n_generations):\n",
        "            self.select_individuals(model,X_train,y_train,X_valid,y_valid)\n",
        "            self.produce_next_generation()\n",
        "            self.best_scores.append(self.best_score)\n",
        " \n",
        "            list_best_fitness.append(self.best_score)\n",
        "            list_mean_fitness.append(np.array(self.fitness_scores).mean())\n",
        "            list_min_fitness.append(np.array(self.fitness_scores).min())\n",
        "\n",
        "            # print(\"All fitnes scores at generation\",i,np.mean(self.fitness_scores))\n",
        "            # print(\"Best Score at generation\",i,self.best_score)\n",
        "            # if (np.mean(self.best_scores[-5:])==self.best_scores[-1]) and (i>=4):\n",
        "            #    break\n",
        "        return  self.best_feature_set,list_best_fitness,\\\n",
        "                list_mean_fitness,list_min_fitness\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKcS7pF3muSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_best_fitness_n=[]\n",
        "list_mean_fitness_n=[]\n",
        "list_min_fitness_n=[]\n",
        "list_res_n=[]\n",
        "def score_model_gen(model,X_train, y_train, X_valid, y_valid):\n",
        "    model.fit(X_train,y_train)\n",
        "    # return log_loss(y_valid,model.predict_proba(X_valid))\n",
        "    P = (model.predict(X_valid) != y_valid).mean()\n",
        "    alpha=0.01\n",
        "    # Compute for the objective function\n",
        "    j = alpha*(X_valid.shape[1]/data_shape)+(1-alpha)*P\n",
        "    return -j\n",
        "for i in range(runs):\n",
        "  print(i)\n",
        "  gaf=GAFeatureSelector(score_model_gen,population_size=10,n_generations=100,mutation_rate=0.08)\n",
        "  res,temp1,temp2,temp3=gaf.fit(clf,X_train, y_train,X_test, y_test)\n",
        "  list_res_n.append(res)\n",
        "  list_best_fitness_n.append(temp1)\n",
        "  list_mean_fitness_n.append(temp2)\n",
        "  list_min_fitness_n.append(temp3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28EnQaJnmvhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.style as style\n",
        "style.use('fivethirtyeight')\n",
        "f ,ax= plt.subplots(1,2,figsize=(13,5))\n",
        "ax[0].plot(np.arange(100),(-np.array(list_best_fitness_n)).mean(axis=0),color='orange',label='Genetic Algorithm')\n",
        "ax[0].plot(np.arange(100),np.array(list_best_fitness_org).mean(axis=0),label='Particle swarm optimization')\n",
        "ax[0].plot(np.arange(100),np.array(list_best_fitness_new).mean(axis=0),color='red',label='Proposed Solution')\n",
        "\n",
        "\n",
        "ax[0].legend(prop={'weight':'bold'} )\n",
        "ax[0].set_title('best fitness mean value across {} runs'.format(runs),{'fontsize':15},pad=5)\n",
        "\n",
        "ax[0].set_ylabel('Fitness scores')\n",
        "ax[0].set_xlabel('Number of Iterations')\n",
        "ax[1].plot(np.arange(100),(-np.array(list_best_fitness_n)).min(axis=0),color='orange',label='Genetic Algorithm')\n",
        "ax[1].plot(np.arange(100),np.array(list_best_fitness_org).min(axis=0),label='Particle swarm optimization')\n",
        "ax[1].plot(np.arange(100),np.array(list_best_fitness_new).min(axis=0),color='red',label='Proposed Solution')\n",
        "\n",
        "ax[1].set_title('best fitness minimum value across {} runs'.format(runs),{'fontsize':15},pad=5)\n",
        "ax[1].set_xlabel('Number of Iterations')\n",
        "ax[1].legend(prop={'weight':'bold'})\n",
        "\n",
        "f.suptitle('{} Data Set'.format('spam mail'),y=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUJVctRbmwyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alld=[np.array(list_best_fitness_new)[:,99],-np.array(list_best_fitness_n)[:,99],np.array(list_best_fitness_org)[:,99]]\n",
        "f ,ax= plt.subplots(figsize=(10,5))\n",
        "plt.boxplot(x=alld)\n",
        "plt.xticks([1,2,3],['Proposed Solution','Genetic Algorithm','Particle swarm optimization'],rotation=15)\n",
        "f.suptitle('{} Data Set , Best fitness values across {} runs'.format('spam mail',runs),y=1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSIjZzw0myGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "org_accuracy=[]\n",
        "for x in list_res_org:\n",
        "  clf.fit(X_train[X_train.columns[np.where(x)]],y_train)\n",
        "  org_accuracy.append((clf.predict(X_test[X_train.columns[np.where(x)]])==y_test).mean())\n",
        "new_accuracy=[]\n",
        "for x in list_res_new:\n",
        "  clf.fit(X_train[X_train.columns[np.where(x)]],y_train)\n",
        "  new_accuracy.append((clf.predict(X_test[X_train.columns[np.where(x)]])==y_test).mean())\n",
        "n_accuracy=[]\n",
        "for x in list_res_n:\n",
        "  clf.fit(X_train[X_train.columns[np.where(x)]],y_train)\n",
        "  n_accuracy.append((clf.predict(X_test[X_train.columns[np.where(x)]])==y_test).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Fw5MR_m20o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( np.round((np.array(list_best_fitness_new)[:,99]).min(),5),' ',np.round((np.array(list_best_fitness_new)[:,99]).max(),5),' ',np.round((np.array(list_best_fitness_new)[:,99]).mean(),5),' ',np.round((np.array(list_best_fitness_new)[:,99]).std(),5),' ',np.array(new_accuracy).mean()   )\n",
        "print( np.round((-np.array(list_best_fitness_n)[:,99]).min(),5),' ',np.round((-np.array(list_best_fitness_n)[:,99]).max(),5),' ',np.round((-np.array(list_best_fitness_n)[:,99]).mean(),5),' ',np.round((-np.array(list_best_fitness_n)[:,99]).std(),5),' ',np.array(n_accuracy).mean()   )\n",
        "print( np.round((np.array(list_best_fitness_org)[:,99]).min(),5),' ',np.round((np.array(list_best_fitness_org)[:,99]).max(),5),' ',np.round((np.array(list_best_fitness_org)[:,99]).mean(),5),' ',np.round((np.array(list_best_fitness_org)[:,99]).std(),5),' ',np.array(org_accuracy).mean()   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhryxBbUm4OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "t,p=stats.ttest_ind(np.array(list_best_fitness_org)[:,99],\n",
        "                np.array(list_best_fitness_new)[:,99] ,equal_var = False)\n",
        "t,p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRG80eozm5ZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "t,p=stats.ttest_ind(-np.array(list_best_fitness_n)[:,99],\n",
        "                np.array(list_best_fitness_new)[:,99] ,equal_var = False)\n",
        "t,p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpxM-AFRG64M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}